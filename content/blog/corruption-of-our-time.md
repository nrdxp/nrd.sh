---
title: The Corruption of Our Time
description: And Expose of Truth Through Contention
taxonomies:
  tags:
    - politics
    - civilization
    - philosophy
date: "2025-07-06"
draft: true
extra:
  read_time: true
  repo_view: true
---

As I've alluded to multiple times now, the last year of my life has been one of the most difficult in my experience. Through this process, I have unwittingly been able to establish for myself, and perhaps for others, a Coherent and internally logically consistent [moral philosophy](../code-of-rebellion). One distinctly unlike many other moral codes, which rely on feeling or assertion without basis for the standard by which to determine an ought. This is, of course, an ancient problem. Religion purports to solve this by introducing an intial giver of moral code. This may suffice for the adherents of a given religion, but to anyone else it is utterly unconvincing and untenable; not to mention the inconsistent quality of the morals being handed down, depending on which religion to which you adhere.

I also mentioned in a previous piece that I have developed my own understanding on the infinitely impenetrable Question of God. That is, precisely, it is a question which has a definitive yes or no answer: either a God does or does not exist; whether we can prove it or not, and whether you personally care or not. However, by the rules and limits of known logic itself, there is a fairly major catch rooted in the ideas first espoused by Gödel in his Incompleteness Theorem. We know that no system of logic can be complete and consistent simultaneously. That is, if there is incoherence (logical contradiction) in a system of logic, it is essentially useless to us totally. The best we can hope for then, is a useful logic which is itself incomplete, that is, it cannot prove every true fact _per se_ within the bounds of its own rules.

Thus, there will then always be statements which are definitetively true or false which can never be proven as such in an incomplete system of logic (the only kind we ever have). We've known this over a century, now, but it would seem to be we haven't even really begun to contend with the implication. This isn't totally surprising when you realize that this finding came much to the chagrin of individuals who were quite convinced, beforehand, that they were right on the heals a "final" logic that could eventually come to explain all things.

But let's digress and come back, for a bit, to the question of God, whether one exists or not. It is a yes or no question, and it has a yes or no answer, logically speaking, but we have, at least as of yet, failed to develop a system of reasoning capable of expressing the conceptualization adequately such that it could be definitetively proven using a rigorous system of logic, and as best we can tell, it isn't even possible to do so barring some radically novel form of maths or reasoning of which we are now totally ignorant. Of course, that didn't stop the emminent Gödel from trying in his ambitious proof of the ontological argument for God's existence; still some take issue with his axiomatic assumptions. The central problem of any logical argument. The answer, then, may forever lay totally outside of our capacity to answer it. Some may argue that this is by the beautiful design of the creator himself, while others might say it is because there is no God at all.

Some may see this as a problem, but if we reframe the problem a bit, it might just provide us with an interesting opportunity to shift focus to a more pragmatic concern, not to attempt to prove a statement which we are utterly incapable, but to instead explore the rigorous boundaries of our own morals, from first principles; as best as we are able. This is, least, what your author has begun to attempt in his aforementioned post.

And in some sense, the stakes couldn't be higher, both in general and particularly in our time, it would seem. Were it possible to resolve the moral presuppositions of the religious with that of the atheist on common ground, bridged by a rigorous logic that both can adhere and freely admit to, then perhaps we can finally know a more perfect peace between the ranks of each camp. If this proves impossible, however, then I can only foresee the endless war continuing as they hopelessly seek to eliminate each other totally. There is, perhaps, an even more important distinction to draw, however. Framing the problem in this way allows for a more nuanced framing of the moral camps, not based on adherence religion or lack thereof, but of moral consistency vs inconsistency, which is a problem rampant on all sides.

And so, understanding that finding the ultimate truth of God's existence is impossible, at least in our present toolbox, we are free to explore this more pragmatic and pressing moral question: can we build a common, unambiguous ground, or if not, can we at least more clearly identitify the lines along which we contend with one another; not lines based on superficiality but of substance? I believe that the key to that commonality rests in logic. You see, as I've already hinted at, the split between religious and atheiest is a bit incoherent, and this distinction may actually end up being a far more important than the question itself. Concretely: some who are religious are quite devout and consistent in the application of the moral tenets of their belief, and some barely even attempt to uphold any sort of consistent morality whatever despite their claims of belief. The same can easily be said for the atheist. One could argue that it is far more appropriate, then, to ally oneself with those who consistently uphold a moral belief, as at least you have substantial (i.e., experiential) common ground.

In simple terms, the "enemy" of the religious or atheist may just be wildly misconceptualized. And this has far more practical implications than the question of God itself, as big as it is. You see, this pattern is consistent all across society; split into superficial camps when, in reality, they have far more in common in their approaches or way of life with those who are supposedly "opposed" t o them, superficially. This happens in politics, in education, in science, and basically every human institution. If you recall the conceptualization of Corruption from the aforementioned piece, you might intuit that this fuzziness only aids it. That is, Corruption as defined by the deliberate amplification or acceleration of Entropy, is aided and abetted by misunderstanding who our _true_ enemies and allies really are in any given context; something that seems profoundly pertitent to the seemingly confused and endless cultural warfare of modern times.

The less ambiguous and more precise we can make this, then, the more powerful those who strive for reason in their own lives may unite together despite their differences, keeping the chaos of incoherence at bay, perhaps, enough to bring some non-trivial improvement in this utterly confused timeline of ours. As is mentioned, this tension is present in all human affairs, between coherence and incoherence, as we have already explored in a previous piece in an at least psuedo-rigorous fashion; establishing from a single axiom of Entropy's existence a formal conceptualization of Justice in an abstract State. We will proceed to build on that foundation here in this work, so it is highly recommended to the interested reader to review at least the first few segments for the definitions of the terms we will use here throughout.

Some of you may feel this is too abstract, and so I will now entice you with my ambitious aim: that by the end of this peice I will bring it squarely down to earth, in what I now see, and will endeavor to demonstrate beyond any reasonable doubt, is the single greatest Corruption of our time, one which most of us have felt and many of us cannot escape in our own lives, your author included. In fact, it is through the pain of struggling and ultimately failing endlessly against this greatest of all Corruptions, for it is one wresting in the very hearts and minds of individuals against the very natural order itself, that has been the greatest teacher of this philosophy. Eventually leading here, quite by accident, to this place where we might now firmly be able to demonstrate, through logic and reason alone, not only its (i.e. the Corruption) existence, but the precise mechanisms of its deceptions.

So buckle up buttercup; or don't. Moral philosophy isn't everyone's bag, admittedly. Some have even gone as far as to dismiss it outright; claiming its authority and potency to have been entirely usurped by science decades ago, by now. Yet there appears no tangible reason why an increase in emperical knowledge would do away with the awesome power of deductive logical reasoning, as applied to human concerns and affairs.

Still further, everyone does appear to have a real and visceral stake it the questions which only philosophy seems adequate to address; it is a universal concern even to those who claim to abhor it. For never has it been seen a single individual in all the world who did not strongly react to what they percieve, rightly or wrongly, as injustice. It is this inherent yurning for justice in our collective souls, then, that I hope to appeal to. Logic, though perhaps a bit exhausting and dry, is one of our most powerful tools in order to bring laser precision and clarity to what is hoped will become clear through this work, is a deliberately confused and obscured state of affairs.

However, we will actually need more than logic alone, that is, we need something to apply it to. We need _context_.

# A Detour Through Data

It has become apparent that, before we shall be able to show through simple logic the veracity of such ambitious claims, that we shall have to expand from where it is we last left. In a previous article we explored my system of moral logic through the lens of Open Source software, a topic which the author cares about, deeply. However, we shall now leave the realm of chosen profession and seek to expand our application of these principles to other areas of reasoning, building up more terminology as we go along.

Data is the buzzword of our time, isn't it? We have more now, of all various types, that at any time in known human history, by far. We have enough data now, that we have even begun to use it to notice patterns on a scale and depth never before thought possible. Many colloquially refer to this process as AI, or machine learning. As we learn more and more about this mysterious process some astounding facts have slowly started to become apparent.

Before we introduce one recent insight that might be of use to our amibitions here, let's explore the concept more generally. If you think about it, data in its naturally unfiltered state is a good analogy for chaos, or entropy. There may be some signal in the noise, but without intention, or some mechanism to filter it, you may never filter it out. Additionally, there is one principle, in particular, which I've come to find critical for our analysis here.

It's fairly simple to elucidate: imagine any method of collecting or visualing data, it could be a noisy tv signal, cosmic background radiation, or even internet activity. Within any given natural (as in unfiltered, uncurated or undirected) data feed, we will suppose, by the very laws of Entropy itself, that we should find much more incoherent data than that which is coherent. That is, much more of the data will have no discernable structure, or logic, or that it might be contradictory in some way, or inaccurate or imprecise, etc, etc.

This concept is fairly simple enough to understand. If it weren't true we wouldn't need to build roads to forge a coherent path across the wilderness, or filter noise to isolate a signal, or remind users on social media that the majority of what they find there may not be wholly reprasentative of the truth. There is something else, however. If we simply follow the laws of basic calculus, you might reason that such a trend would become more pronounced at scale.

That is, the more information you collect in a system, given this principle that more of it will be incoherent than coherent, then you might imagine that this problem becomes exponential. So, as super large quantities of data are amassed, you might say that the amount of coherent information as a total percentage of the whole tends, without any sort of directed filtering mechanism, toward 0. In simple terms, the more data you collect, the more exponentially difficult it becomes to separate the wheat from the chaff, simply because there is so much of the latter, obscuring the presence of the former; a needle in a hay stack where the needles are fewer and more far between in an exponentially growing pile of hay.

We might posit further that this is, actually, the underlying cause of the AI phenomenon known as "hallucinations". It's also the same principle, in my estimation, behind the modern concept of "information overload" which causes an individual to become disoriented or confused after taking in far too much information to coherently process in too short a time.

If we try, at a high level at least, to compare how these systems work to our own minds, we might begin to to see why this might be. A machine learning algorithm, in simple terms, is trained to recognize all sorts of various kinds of patterns or "correlations", you might say, between the data fed to it. The process known as "training" is simply a computationally intensive mechanism to distinguish these connections across various dimensions and then create a sort of map (known as encodings in some schemes) to be able to refer back to a probabalistic distribution of patterns and their overall percentage of occurence. That might be a mouthful still, so imagine the subconscious mind, rapidly accessing the vast amounts of information sent to it via the senses, drawing all sorts of patterns across various dimensions.

In the case of LLMs then, we can use this encoded map to make predictions about which words are most likely to follow certain other words. In a perfect world, where every single piece of data it is trained over is verified to be 100% coherent (as in logical, or true or consistent), we might imagine these encodings to themselves approach perfection. That is, we hypothesize that in such a scenario hallucinations not only wouldn't happen, but that they would be utterly impossible barring some imperfection in the probability calculations. This would be like living in a perfect world where the patterns our subconscious mind draws up are always an accurate representation of the underlying reality.

This is, however, not the case in our imperfect reality, as we know from experience. The subconscious mind cannot even rightly determine whether it is waking or sleeping, or whether or not the information which it is drawing connections over is "real" or perhaps you might say "correct" in some higher sense.

However, we may have some interesting new evidence to suggest that these higher realms or states actually do exist, after all, even if we cannot percieve them experientially. In a, in your author's humble opinion at least, rather groundbreaking new study, evidence for Plato's forms has actually be discovered in practice; almost by accident. A finding that is rather ironic given that his idea of idealized forms had largely been dismissed for a millenia, at least. As delving into the specifics would likely take the entire rest of this post, I'll just briefly mention that these forms are not exactly like Plato's conception. In the [paper](https://arxiv.org/html/2405.07987v1/), it was shown that they are malleable, that is, they morph grow or change with reality itself, and we can, with our models, or in the case of this particularly paper, their "encodings", only approximate them.

I'll make some effort to clarify this at least, for those unfamiliar with the concept. Plato postulated that there must exist, in some higher realm or space, "ideal" forms of various entities found in nature. Concretely, Plato suggests that there is an ideal conception of a "man", a "woman", or even a an abstract concept such as a "circle", or even an entire discipline such as "physics". Nature, then, models itself after these higher forms, imitating them with varying degrees of accuracy. As stated, this idea had largely been dismissed for an age, yet researchers are now able to use these supposedly non-existent forms to translate encodings between disparate models (that is, entirely different algorithms trained on entirely different data sets); a feat that should be impossible were it not for the existence of these higher forms in some space which we are, as of yet, unequiped to perfectly understand or articulate (and least here in this article).

But let's digress for a bit. I mentioned a bit ago that in the "ideal" scenario of perfect data, you could make perfect predictions. Now this may be impossible in the final analysis, but as we just briefly explored, there may be some higher conceptualization of this model which actually exists, and which machine learning models now are only poorly imitating, and thus we should be able to test it. In order to do that, however, we have to understand what it is that's missing, or rather, how we could create a system that could possibly stand a chance at coherently "filtering" the inputs at the scale necessary to train these models; or in platonic terms, how can we design our models to more accurately depict their ideal formulations? Let's compare these machines, once more, to our own minds to see if we can find a clue as to what might possibly be missing, shall we? Indeed, we have already hinted at it, if you've followed closely...

As I described earlier, these models create schemes or encodings of relations between its input data at scale. The larger the computationl prowess, the more deeply the connections can be ascertained, or the more dimensions which we can draw correlations, if you prefer. There is a key difference here, between how the models draw relations and how our own minds do. In a human mind, there are myriad of "sensors" (senses, emotions, thoughts, etc, etc) which come at us every second of every day whether we are ready for it, or not. Consciously processing all of that data would be nearly impossible, so instead our brain makes a deliberate effort to filter, at least consciously, a large majority of it out.

Just think about how the your eyes work, for a moment. You focus on a single point at a time. Even with a much wider perifery available, your intent and focus can only really reside in a single point, and the further away from the focal point a given phenomenon, the more imprecise the estimation our minds draw. In simple terms, if a cat moves quickly across the road and I'm focusing intently on it, I can see clearly that it is, in fact, a cat. If I am looking at my lawn, however, and see the cat only from the corner of my eye, I likely won't even be able to tell clearly that it is a cat at all. I might guess its a cat, based on other factors like speed, or color, but I did not focus intently enough to be 100% certain, like I would be if I were looking directly at it.

This simply example hopefully illustrates the point. If we tried to extend (however inadequately) our analogy to ML models, you might say that the machine has no mechanism to truly focus. If we use our subconscious analogy from before, it cannot determine, using conscious intent, whether it is dreaming (i.e. hallucinating) or awake (i.e. telling the truth). Other than relational cues similar to seeing our cat in the corner of our eye, it has no mechanism to distinguish which data in its set is worth focusing on, or coherent or incoherent, correct or incorrect etc, etc. Of course, in actual application this is far more nuanced. For one thing, large models today are fine-tuned after training, and one might say this is at least a crude form of "focusing" in on a more deliberate intent or purpose. For another, as we saw in our human example, focus itself doesn't neccesitate total coherence. If we are so busy focusing on the cat that we get hit by a truck, you might say we've had a significant moral failing, or lapse in judgement. Without some sort of deliberate model, however, we might struggle to say precisely _why_ we see it as a moral failing. Perhaps the astute reader sees now, already, where we are heading next...

Before going further, however, let's just review to ensure we are all on the same page. We know our minds have mechanisms to filter noise, and we even build machines to do this for us in some applications as well. Our first stab at language models, however, have basically no conception of focus whatever, minus some fairly crude (i.e. inflexible) fine tuning mechanisms after the fact. Further, we established that regardless of the mechanism of our focus, whether it is eyesight, or logic, or some other mechanism by which we can move toward coherence from incoherence, that we can still end up in an incoherent state at the end (i.e. getting hit by a truck even while focusing intently on the cat). Thus even our friendly logic is not enough, all by itself at least, as proud as your author might be of his little accomplishment illucidating a rigorous definition of Justice. We must know how to _apply_ it in such a way as to produce an ultimately coherent result. In other words, we need some context in which to apply our logic concretely. Those familiar with the concept of the _type_ vs _term_ level here may have some advantage. We must take an abstract representation of a tihng, in this case our State (i.e. an abstract type), and create a concrete context to apply it against (i.e. a concrete term which statisfies it).

As complex as this sounds, there is a rather simple and elegant solution, one that many engineers and those of the computational persuasion may already be intimately familiar with, though not always fond of. You might term it hierarchy in one context, or recursion in another, but the idea is simply that we must organize our focus based on a set of priorities. Sticking with our cat example, we might have an interest in knowing what it is which is running across the road at great speed, but not as much as we don't want to get hit by a bus. Not dying, unequivocally takes the priority. Hopefully this example is visceral enough to convince even the skeptics of heirarchy of its unambiguous usefulness, at least in certain contexts. That is, not dying becomes the _priority_ and should demand our _immediate_ coherent focus or attention, even if we must remove that focus from something we were previously interested in investigating if we are to avoid a very incoherent situation (i.e. a rather messy death).

Much like the authors in the aforementioned paper suggest, the higher Platonic form, or ideal, of hierarchy will itself, not remain static, but will inevitably be dynamically shaped by reality itself. To give a concrete example building off our analogy so far, imagine if one day we became cyborgs and had nearly indestructable bodies to the point that a bus couldn't hurt or even particularly harm us; we might, at that point, choose to prioritize our curiousity concerning the cat over the now triviality of the impending bus impact. An admittedly contrive example, but hopefully one that illustrates the point clearly. If we endeavor to suggest that what should be our priority is itself one of these forms then, in some higher conceptual space, then we can imagine that what our highest priority should be, and the order of any given priority with respect to another, is itself a dynamic and ever changing process, but that even so, it's form (or perhaps expression) is real and unambiguous, at least at a particular point in time. If we stop here and just ponder this for a second, the implications are profound enough to give us some pause as we reflect back on the illustrated chaos in our time from earlier in the article and undoubtably our own experience.

For example, many people are staunchly pro democracy, and for many years it has seemed to serve us rather well and faithfully, even despite Socrates ancient chastisement and warning of the practice. However, as the environment changes into something entirely novel and unfamiliar; even uncomparable to any time in the human past, it seems more and more like this "democratic" process has become nothing but a form of tyranny by imprenetrable beauracracy. One that ensures that we keep spending far beyond our capacity, and stifles any and all attempts to halt or even slow the progression toward complete and utter incoherence, by the shere cost and resistance to change. You may not agree with that statement, but it is offered here only as an example to help us get our minds flexing. To be clear, I use democracy here as a provacative example to draw attention to the real world implications, not necessarily to condemn the practice, outright.

In all reality, a more coherent political system of the future would likely look a lot more like a modern demoncracy than it would a modern dictatorship, though with some well adjusted tweaks for taming beauracracy, perhaps. The point, however, is that what once was a valid and useful priority in our hierarchy of how to organize our political system has now begun to show itself to be quite damaging, at least in it's current form. In the terms we have introduced so far: the Platonic ideal of what we should prioritize has slowly been shifting out from under us, and our inability to adapt to its new "shape" has left us in a rather dire, nearly suicidal situation, or so one might suggest.

But what is this all for? Though you might now suspect it, we are not here proposing that it is democracy that is the greatest corruption of our time, specifically, no. Rather we are illustrating the landscape of these still somewhat novel AI systems using some rather astounding new findings, and hopefully in terms even non-experts can comprehend. And what is AI, again? Well largely in its current form, at least, it's simply a system to draw correlations and relations across vast pools of data, across arbitrary dimensions. Now that we have explored the concept a bit, and reintroduced some previously condemned notions from ancient philosophy, we may just be prepared to reconcile this understanding from the point at which we began: that is a consistent moral framework in need of _context_ coherently applied.

(to be continued)
